{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93511f4-d721-48e9-8f6a-d01be90bf521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'LLaMA-Factory'...\n",
      "remote: Enumerating objects: 361, done.\u001b[K\n",
      "remote: Counting objects: 100% (361/361), done.\u001b[K\n",
      "remote: Compressing objects: 100% (273/273), done.\u001b[K\n",
      "remote: Total 361 (delta 79), reused 312 (delta 73), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (361/361), 9.94 MiB | 5.43 MiB/s, done.\n",
      "Resolving deltas: 100% (79/79), done.\n",
      "/home/pramod/work/alma/Specialized-LLM-Bot/LLaMA-Factory\n",
      "\u001b[0m\u001b[01;34massets\u001b[0m/       \u001b[01;34mevaluation\u001b[0m/  MANIFEST.in     requirements.txt  \u001b[01;34mtests\u001b[0m/\n",
      "CITATION.cff  \u001b[01;34mexamples\u001b[0m/    pyproject.toml  \u001b[01;34mscripts\u001b[0m/\n",
      "\u001b[01;34mdata\u001b[0m/         LICENSE      README.md       setup.py\n",
      "\u001b[01;34mdocker\u001b[0m/       Makefile     README_zh.md    \u001b[01;34msrc\u001b[0m/\n",
      "Obtaining file:///home/pramod/work/alma/Specialized-LLM-Bot/LLaMA-Factory\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0,<=4.52.4,>=4.45.0 (from llamafactory==0.9.4.dev0)\n",
      "  Using cached transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting datasets<=3.6.0,>=2.16.0 (from llamafactory==0.9.4.dev0)\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting accelerate<=1.7.0,>=1.3.0 (from llamafactory==0.9.4.dev0)\n",
      "  Using cached accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting peft<=0.15.2,>=0.14.0 (from llamafactory==0.9.4.dev0)\n",
      "  Using cached peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting trl<=0.9.6,>=0.8.6 (from llamafactory==0.9.4.dev0)\n",
      "  Using cached trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting tokenizers<=0.21.1,>=0.19.0 (from llamafactory==0.9.4.dev0)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting gradio<=5.31.0,>=4.38.0 (from llamafactory==0.9.4.dev0)\n",
      "  Using cached gradio-5.31.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting scipy (from llamafactory==0.9.4.dev0)\n",
      "  Using cached scipy-1.16.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
      "Collecting einops (from llamafactory==0.9.4.dev0)\n",
      "  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting sentencepiece (from llamafactory==0.9.4.dev0)\n",
      "  Using cached sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting tiktoken (from llamafactory==0.9.4.dev0)\n",
      "  Using cached tiktoken-0.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting protobuf (from llamafactory==0.9.4.dev0)\n",
      "  Using cached protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting uvicorn (from llamafactory==0.9.4.dev0)\n",
      "  Using cached uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting fastapi (from llamafactory==0.9.4.dev0)\n",
      "  Downloading fastapi-0.115.14-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting sse-starlette (from llamafactory==0.9.4.dev0)\n",
      "  Downloading sse_starlette-2.3.6-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting matplotlib>=3.7.0 (from llamafactory==0.9.4.dev0)\n",
      "  Using cached matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting fire (from llamafactory==0.9.4.dev0)\n",
      "  Using cached fire-0.7.0-py3-none-any.whl\n",
      "Collecting omegaconf (from llamafactory==0.9.4.dev0)\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: packaging in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from llamafactory==0.9.4.dev0) (25.0)\n",
      "Requirement already satisfied: pyyaml in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from llamafactory==0.9.4.dev0) (6.0.2)\n",
      "Collecting numpy<2.0.0 (from llamafactory==0.9.4.dev0)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting pydantic<=2.10.6 (from llamafactory==0.9.4.dev0)\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pandas>=2.0.0 (from llamafactory==0.9.4.dev0)\n",
      "  Using cached pandas-2.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting av (from llamafactory==0.9.4.dev0)\n",
      "  Using cached av-14.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
      "Collecting librosa (from llamafactory==0.9.4.dev0)\n",
      "  Using cached librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting tyro<0.9.0 (from llamafactory==0.9.4.dev0)\n",
      "  Using cached tyro-0.8.14-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting torch>=2.0.0 (from llamafactory==0.9.4.dev0)\n",
      "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting torchvision>=0.15.0 (from llamafactory==0.9.4.dev0)\n",
      "  Downloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting bitsandbytes>=0.39.0 (from llamafactory==0.9.4.dev0)\n",
      "  Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: psutil in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (7.0.0)\n",
      "Collecting huggingface-hub>=0.21.0 (from accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0)\n",
      "  Downloading huggingface_hub-0.33.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting safetensors>=0.4.3 (from accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting filelock (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.32.4)\n",
      "Collecting tqdm>=4.66.3 (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (4.9.0)\n",
      "Collecting ffmpy (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
      "  Downloading ffmpy-0.6.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.10.1 (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached gradio_client-1.10.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.0.2)\n",
      "Collecting orjson~=3.0 (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached orjson-3.10.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting pillow<12.0,>=8.0 (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting pydub (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting ruff>=0.9.3 (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
      "  Downloading ruff-0.12.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
      "  Downloading starlette-0.47.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (4.14.0)\n",
      "Collecting websockets<16.0,>=10.0 (from gradio-client==1.10.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached fonttools-4.58.4-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (106 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<=2.10.6->llamafactory==0.9.4.dev0)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<=2.10.6->llamafactory==0.9.4.dev0)\n",
      "  Using cached pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: setuptools in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from torch>=2.0.0->llamafactory==0.9.4.dev0) (80.9.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers!=4.46.*,!=4.47.*,!=4.48.0,!=4.52.0,<=4.52.4,>=4.45.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting docstring-parser>=0.16 (from tyro<0.9.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rich>=11.1.0 (from tyro<0.9.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro<0.9.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting click>=7.0 (from uvicorn->llamafactory==0.9.4.dev0)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: h11>=0.8 in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from uvicorn->llamafactory==0.9.4.dev0) (0.16.0)\n",
      "Collecting termcolor (from fire->llamafactory==0.9.4.dev0)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa->llamafactory==0.9.4.dev0)\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting numba>=0.51.0 (from librosa->llamafactory==0.9.4.dev0)\n",
      "  Using cached numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting scikit-learn>=1.1.0 (from librosa->llamafactory==0.9.4.dev0)\n",
      "  Using cached scikit_learn-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Collecting joblib>=1.0 (from librosa->llamafactory==0.9.4.dev0)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from librosa->llamafactory==0.9.4.dev0) (5.2.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa->llamafactory==0.9.4.dev0)\n",
      "  Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa->llamafactory==0.9.4.dev0)\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa->llamafactory==0.9.4.dev0)\n",
      "  Using cached soxr-0.5.0.post1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting lazy_loader>=0.1 (from librosa->llamafactory==0.9.4.dev0)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa->llamafactory==0.9.4.dev0)\n",
      "  Downloading msgpack-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->llamafactory==0.9.4.dev0)\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Requirement already satisfied: idna>=2.8 in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.3.1)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached aiohttp-3.12.13-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: certifi in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.0.9)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub>=0.21.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0)\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.0->librosa->llamafactory==0.9.4.dev0)\n",
      "  Using cached llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from pooch>=1.1->librosa->llamafactory==0.9.4.dev0) (4.3.8)\n",
      "Requirement already satisfied: six>=1.5 in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from requests>=2.32.2->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from requests>=2.32.2->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.5.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.4.dev0) (2.19.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.1.0->librosa->llamafactory==0.9.4.dev0)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from soundfile>=0.12.1->librosa->llamafactory==0.9.4.dev0) (1.17.1)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.0.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0)\n",
      "  Downloading multidict-6.5.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: pycparser in /home/pramod/work/alma/Specialized-LLM-Bot/env/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->llamafactory==0.9.4.dev0) (2.22)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.4.dev0)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl (67.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Using cached gradio-5.31.0-py3-none-any.whl (54.2 MB)\n",
      "Using cached gradio_client-1.10.1-py3-none-any.whl (323 kB)\n",
      "Downloading fastapi-0.115.14-py3-none-any.whl (95 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.5/95.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "Using cached pandas-2.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "Using cached peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached trl-0.9.6-py3-none-any.whl (245 kB)\n",
      "Using cached tyro-0.8.14-py3-none-any.whl (109 kB)\n",
      "Using cached uvicorn-0.34.3-py3-none-any.whl (62 kB)\n",
      "Using cached av-14.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.5 MB)\n",
      "Using cached einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Using cached librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Using cached scipy-1.16.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.1 MB)\n",
      "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Using cached protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
      "Using cached sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Downloading sse_starlette-2.3.6-py3-none-any.whl (10 kB)\n",
      "Using cached tiktoken-0.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached fonttools-4.58.4-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading huggingface_hub-0.33.1-py3-none-any.whl (515 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.4/515.4 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.9/426.9 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
      "Using cached orjson-3.10.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (133 kB)\n",
      "Using cached pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Using cached pyarrow-20.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading ruff-0.12.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Using cached scikit_learn-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Using cached shtab-1.7.2-py3-none-any.whl (14 kB)\n",
      "Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "Using cached soxr-0.5.0.post1-cp312-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (248 kB)\n",
      "Using cached starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading ffmpy-0.6.0-py3-none-any.whl (5.5 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached aiohttp-3.12.13-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading multidict-6.5.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (251 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
      "Using cached yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
      "Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: llamafactory\n",
      "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llamafactory: filename=llamafactory-0.9.4.dev0-0.editable-py3-none-any.whl size=27640 sha256=9428929f8d5407b8b44397e39e263243cac5f004e1f5bbe626ff161435c2bc18\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-1hdw0_2k/wheels/8d/2b/54/c7a83f9aac7c2b9694f262bef5206a39d63a3c100f2a64b691\n",
      "Successfully built llamafactory\n",
      "Installing collected packages: sentencepiece, pytz, pydub, nvidia-cusparselt-cu12, mpmath, antlr4-python3-runtime, xxhash, websockets, tzdata, triton, tqdm, tomlkit, threadpoolctl, termcolor, sympy, shtab, shellingham, semantic-version, safetensors, ruff, regex, python-multipart, pyparsing, pydantic-core, pyarrow, protobuf, propcache, pillow, orjson, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, msgpack, mdurl, llvmlite, lazy_loader, kiwisolver, joblib, hf-xet, groovy, fsspec, frozenlist, fonttools, filelock, ffmpy, einops, docstring-parser, dill, cycler, click, av, audioread, annotated-types, aiohappyeyeballs, aiofiles, yarl, uvicorn, tiktoken, starlette, sse-starlette, soxr, soundfile, scipy, pydantic, pooch, pandas, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, numba, multiprocess, markdown-it-py, huggingface-hub, fire, contourpy, aiosignal, tokenizers, scikit-learn, safehttpx, rich, nvidia-cusolver-cu12, matplotlib, gradio-client, fastapi, aiohttp, tyro, typer, transformers, torch, librosa, torchvision, gradio, datasets, bitsandbytes, accelerate, trl, peft, llamafactory\n",
      "Successfully installed accelerate-1.7.0 aiofiles-24.1.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.13 aiosignal-1.3.2 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 audioread-3.0.1 av-14.4.0 bitsandbytes-0.46.0 click-8.2.1 contourpy-1.3.2 cycler-0.12.1 datasets-3.6.0 dill-0.3.8 docstring-parser-0.16 einops-0.8.1 fastapi-0.115.14 ffmpy-0.6.0 filelock-3.18.0 fire-0.7.0 fonttools-4.58.4 frozenlist-1.7.0 fsspec-2025.3.0 gradio-5.31.0 gradio-client-1.10.1 groovy-0.1.2 hf-xet-1.1.5 huggingface-hub-0.33.1 joblib-1.5.1 kiwisolver-1.4.8 lazy_loader-0.4 librosa-0.11.0 llamafactory-0.9.4.dev0 llvmlite-0.44.0 markdown-it-py-3.0.0 matplotlib-3.10.3 mdurl-0.1.2 mpmath-1.3.0 msgpack-1.1.1 multidict-6.5.1 multiprocess-0.70.16 networkx-3.5 numba-0.61.2 numpy-1.26.4 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 omegaconf-2.3.0 orjson-3.10.18 pandas-2.3.0 peft-0.15.2 pillow-11.2.1 pooch-1.8.2 propcache-0.3.2 protobuf-6.31.1 pyarrow-20.0.0 pydantic-2.10.6 pydantic-core-2.27.2 pydub-0.25.1 pyparsing-3.2.3 python-multipart-0.0.20 pytz-2025.2 regex-2024.11.6 rich-14.0.0 ruff-0.12.1 safehttpx-0.1.6 safetensors-0.5.3 scikit-learn-1.7.0 scipy-1.16.0 semantic-version-2.10.0 sentencepiece-0.2.0 shellingham-1.5.4 shtab-1.7.2 soundfile-0.13.1 soxr-0.5.0.post1 sse-starlette-2.3.6 starlette-0.46.2 sympy-1.14.0 termcolor-3.1.0 threadpoolctl-3.6.0 tiktoken-0.9.0 tokenizers-0.21.1 tomlkit-0.13.3 torch-2.7.1 torchvision-0.22.1 tqdm-4.67.1 transformers-4.52.4 triton-3.3.1 trl-0.9.6 typer-0.16.0 tyro-0.8.14 tzdata-2025.2 uvicorn-0.34.3 websockets-15.0.1 xxhash-3.5.0 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
    "%cd LLaMA-Factory\n",
    "%ls\n",
    "!pip install -e .[torch,bitsandbytes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d2f828-0730-4918-9fc5-fcebefa3524f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 27 12:14:46 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        Off |   00000000:02:00.0  On |                  N/A |\n",
      "|  0%   37C    P8             19W /  350W |     626MiB /  24576MiB |     10%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            3576      G   /usr/lib/xorg/Xorg                      200MiB |\n",
      "|    0   N/A  N/A            3892      G   /usr/bin/gnome-shell                     37MiB |\n",
      "|    0   N/A  N/A            4405      G   ...exec/xdg-desktop-portal-gnome         38MiB |\n",
      "|    0   N/A  N/A           71369      G   ...ess --variations-seed-version         16MiB |\n",
      "|    0   N/A  N/A         1261212      G   /opt/google/chrome/chrome                 4MiB |\n",
      "|    0   N/A  N/A         1261270      G   ...ersion=20250625-180038.486000         90MiB |\n",
      "|    0   N/A  N/A         1381955      G   ...521/opt/brave.com/brave/brave          4MiB |\n",
      "|    0   N/A  N/A         1382015      G   ...e37dc6e8b46dc9e7ecef07a161178         67MiB |\n",
      "|    0   N/A  N/A         1392520      G   /usr/share/code/code                     71MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f42727d-5c25-4a01-8596-d6967ffa82c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pramod/work/alma/Specialized-LLM-Bot/LLaMA-Factory\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd776263-766a-45fa-9cb2-eab08455d90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visit http://ip:port for Web UI, e.g., http://127.0.0.1:7860\n",
      "* Running on local URL:  http://0.0.0.0:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    }
   ],
   "source": [
    "!llamafactory-cli webui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39824ceb-3d65-4a4b-9203-bb9e4d43fef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
